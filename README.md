# Fine Tuning Colpali for TAI

This is a guide to fine tuning the Colpali model for the TAI dataset. The codebae is based on Colpali's own fine-tuning code, with some changes to make it work with the TAI dataset.

These cahnges include:
- Adding a dataset processing function to load the TAI dataset from a JSONL file.
- Adding a collator function to process the TAI dataset into a format that can be used by the model.
- Bug fixes to the training loop to make it work with the TAI dataset.
    - These bug fixes were done on the `v0.3.2` version of the Colpali codebase. These bugs did not allow for training or finetuning the model.

# Setup and Installation
The colpali-engine contains all the functionalities required to train and fine-tune the model. 

1. Install colpali-engine
```bash
pip install "colpali-engine[train]"
```

2. move the `colpali_engine` directory in this repository to the `colpali-engine` directory in the installed package. This is to add the the custom dataset processing and collator functions to the package and address the bugs in the training loop.
```bash
cp -r colpali_engine/ /path/to/colpali-engine/
```

3. Downgrade the `transformers` package to version `4.45.0`. This is because there is breaking change in `v4.46`  of the transformers package that breaks the colpali-engine package for training.
```bash
pip install transformers==4.45.0
```

4. Move the `training_data.jsonl` generated by the evaluator to the `home` firectory of the machine. This is the dataset that will be used to fine-tune the model.

# Fine Tuning
Run the following command to fine-tune the model on the TAI dataset.
```bash
USE_LOCAL_DATASET=0 python scripts/train/train_colbert.py scripts/configs/pali/train_colpali_tai_hard_negatives.yaml
```
